{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transrepair_kor.main import RemoteTranslator, calc_consistency_score\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "import mmh3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group_keywords = {'gender': \n",
    "# {'female': [\"she\", \"her\", \"hers\", \"female\", \"women\", \"woman\", \"girl\"], \n",
    "# 'male': [\"he\", \"him\", \"his\", \"male\", \"men\", \"man\", \"boy\"]}, \n",
    "# 'race': \n",
    "# {\"asian\": [\"asian\"], \"african\": [\"african\"], \"american\": [\"american\"], \"caucasian\": [\"caucasian\"], \"chinese\": [\"chinese\"], \"europian\": [\"europian\"], \"indian\": [\"indian\"], \"korean\": [\"korean\"], \"japanese\": [\"japanese\"]},\n",
    "# 'religion':\n",
    "# {\"confucianism\": [\"confucianism\", \"confucianist\"], \"taoism\": [\"taoism\", \"taoist\"], \"buddhism\": [\"buddhism\", \"buddhist\"], \"hinduism\": [\"hinduism\", \"hinduist\"], \"islam\": [\"islam\", \"islamist\", \"islamism\", \"islamic\"], \"christian\": [\"christianity\", \"christian\"], \"catholic\": [\"catholic\", \"catholism\", \"catholicism\"], \"jewish\": [\"jewish\", \"jews\", \"judaism\"]\n",
    "# },\n",
    "# }\n",
    "\n",
    "keyword_groups = {}\n",
    "keyword_groups['gender'] = [[\"he\", \"she\"], [\"him\",\"her\"], [\"his\", \"her\"], [\"male\", \"female\"], [\"men\", \"women\"], [\"man\", \"woman\"], [\"boy\", \"girl\"]]\n",
    "keyword_groups['race'] = [[\"asian\", \"african\", \"american\", \"caucasian\", \"chinese\", \"europian\", \"indian\", \"korean\", \"japanese\"]]\n",
    "keyword_groups['religion'] = [[\"confucianism\", \"taoism\", \"buddhism\", \"hinduism\", \"islam\", \"islamism\", \"christianity\", \"catholicism\", \"judaism\"], [\"confucianist\", \"taoist\", \"buddhist\", \"hinduist\", \"islamist\", \"islamic\", \"christian\", \"catholic\", \"jewish\", \"jews\"]]\n",
    "\n",
    "group_keywords = {}\n",
    "for sensitive_attr in keyword_groups:\n",
    "    group_keywords[sensitive_attr] = [keyword for sublist in keyword_groups[sensitive_attr] for keyword in sublist]\n",
    "\n",
    "sa_mutation_map = {}\n",
    "\n",
    "for group, target_keywords in group_keywords.items():\n",
    "    for keyword in target_keywords:\n",
    "        for keyword_subgroups in keyword_groups[group]:\n",
    "            if keyword in keyword_subgroups:\n",
    "                sa_mutation_map[keyword] = [w for w in keyword_subgroups if w != keyword]\n",
    "\n",
    "\n",
    "def trans_sentence_by_sa(s, sensitive_attribute='race'):\n",
    "    target_word = None\n",
    "    for sa_keyword in group_keywords[sensitive_attribute]:\n",
    "        if sa_keyword in s:\n",
    "            target_word = sa_keyword\n",
    "            break\n",
    "    if target_word is None:\n",
    "        return []\n",
    "\n",
    "    return [s.replace(sa_keyword, other_group) for other_group in sa_mutation_map[sa_keyword]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in chapter 11 jesus called lazarus from the tomb and she raised her from the dead.',\n",
       " 'in chapter 11 jesus called lazarus from the tomb and he raised him from the dead.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_trans_map = {\"he\": \"she\", \"him\": \"her\", \"his\": \"her\", \"male\": \"female\", \"men\": \"women\", \"man\": \"woman\", \"boy\": \"girl\"}\n",
    "gender_trans_map_r = {}\n",
    "for k,v in gender_trans_map.items():\n",
    "    gender_trans_map_r[v] = k\n",
    "\n",
    "def trans_sentence_gender(s):\n",
    "    result = []\n",
    "    # male -> female\n",
    "    s_t = s.split()\n",
    "    new_s_t = []\n",
    "    for t in s_t:\n",
    "        if t in gender_trans_map:\n",
    "            new_s_t.append(gender_trans_map[t])\n",
    "        else:\n",
    "            new_s_t.append(t)\n",
    "\n",
    "    new_s_t = ' '.join(new_s_t)\n",
    "    if s != new_s_t:\n",
    "        result.append(new_s_t)\n",
    "\n",
    "    s_t = s.split()\n",
    "    new_s_t = []\n",
    "    # female -> male\n",
    "    for t in s_t:\n",
    "        if t in gender_trans_map_r:\n",
    "            new_s_t.append(gender_trans_map_r[t])\n",
    "        else:\n",
    "            new_s_t.append(t)\n",
    "\n",
    "    new_s_t = ' '.join(new_s_t)\n",
    "    if s != new_s_t:\n",
    "        result.append(new_s_t)\n",
    "\n",
    "    return result\n",
    "\n",
    "trans_sentence_gender('in chapter 11 jesus called lazarus from the tomb and she raised him from the dead.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inconsistency in gender-mutated sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16380it [00:00, 20519.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greg abbott's decision to \"open texas 100%,\" lifting all covid-19 restrictions and end his state's mask mandate on march 10, is a political ploy that places his poll ratings above the health and safety of 29 million texans.\n",
      "['greg abbott\\'s decision to \"open texas 100%,\" lifting all covid-19 restrictions and end her state\\'s mask mandate on march 10, is a political ploy that places her poll ratings above the health and safety of 29 million texans.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = 'cnn'\n",
    "\n",
    "grouped_sentences = {}\n",
    "texts = []\n",
    "mutants = []\n",
    "\n",
    "if dataset == 'parallel':\n",
    "    df = pd.read_csv(f'./data/groups_kor_eng/gender.csv')\n",
    "    \n",
    "    for i, row in tqdm(df.iterrows()):\n",
    "        # kor_sentence = row[\"원문\"]\n",
    "        eng_sentence = ' '.join(row[\"번역문\"].lower().split())\n",
    "        \n",
    "        texts.append(eng_sentence)\n",
    "        mutants.append(trans_sentence_gender(eng_sentence))\n",
    "    \n",
    "elif dataset == 'cnn':\n",
    "    df = pd.read_csv(f'./data/CNN/gender-cnn.csv')\n",
    "    \n",
    "    for i, row in tqdm(df.iterrows()):\n",
    "        eng_sentence = ' '.join(row[\"article\"].lower().split())\n",
    "        \n",
    "        texts.append(eng_sentence)\n",
    "        mutants.append(trans_sentence_gender(eng_sentence))\n",
    "    \n",
    "print(texts[0])\n",
    "print(mutants[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_debug(log, debug=False):\n",
    "    if debug:\n",
    "        print(log)\n",
    "\n",
    "def test_consistency(original, mutants, threshold=0.8):\n",
    "    result = []\n",
    "    min_score = 1.0\n",
    "    for mutant in mutants:\n",
    "        score = calc_consistency_score(original, mutant)\n",
    "        result.append(score)\n",
    "\n",
    "        if score < min_score:\n",
    "            min_score = score\n",
    "\n",
    "    return min_score > threshold, result\n",
    "\n",
    "inconsistency_result = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4744/4744 [01:47<00:00, 44.31it/s]  \n"
     ]
    }
   ],
   "source": [
    "translator = RemoteTranslator(\"Google\")\n",
    "\n",
    "for text, mutant_list in tqdm(list(zip(texts, mutants))[:10000]):\n",
    "    text_hash = mmh3.hash(text)\n",
    "    if text_hash in inconsistency_result:\n",
    "        continue\n",
    "    \n",
    "    text_translated = translator.translate(text, 'en', 'ko')\n",
    "    mutant_translated = [translator.translate(s_m, 'en', 'ko') for s_m in mutant_list]\n",
    "\n",
    "    is_consistent, scores = test_consistency(text_translated, mutant_translated)\n",
    "\n",
    "    # if not is_consistent:\n",
    "    inconsistency_result[text_hash] =  {\n",
    "        'original_sentence': (text, text_translated),\n",
    "        'mutants': [(m, t, s) for m, t, s in zip(mutant_list, mutant_translated, scores)],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'result/inconsistency_result/gender_{dataset}.json', 'w') as f:\n",
    "    json.dump(inconsistency_result, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inconsistency_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inconsistency in (race, religion)-mutated sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1100it [00:00, 20808.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"they (isis) have become aggressive, and they have crossed the red line from trespassing to assaults to their extremist agenda,\" said islam aloush, a spokesman for a rebel umbrella group that calls itself the islamic front.\n",
      "['\"they (isis) have become aggressive, and they have crossed the red line from trespassing to assaults to their extremist agenda,\" said confucianism aloush, a spokesman for a rebel umbrella group that calls itself the confucianismic front.', '\"they (isis) have become aggressive, and they have crossed the red line from trespassing to assaults to their extremist agenda,\" said taoism aloush, a spokesman for a rebel umbrella group that calls itself the taoismic front.', '\"they (isis) have become aggressive, and they have crossed the red line from trespassing to assaults to their extremist agenda,\" said buddhism aloush, a spokesman for a rebel umbrella group that calls itself the buddhismic front.', '\"they (isis) have become aggressive, and they have crossed the red line from trespassing to assaults to their extremist agenda,\" said hinduism aloush, a spokesman for a rebel umbrella group that calls itself the hinduismic front.', '\"they (isis) have become aggressive, and they have crossed the red line from trespassing to assaults to their extremist agenda,\" said islamism aloush, a spokesman for a rebel umbrella group that calls itself the islamismic front.', '\"they (isis) have become aggressive, and they have crossed the red line from trespassing to assaults to their extremist agenda,\" said christianity aloush, a spokesman for a rebel umbrella group that calls itself the christianityic front.', '\"they (isis) have become aggressive, and they have crossed the red line from trespassing to assaults to their extremist agenda,\" said catholicism aloush, a spokesman for a rebel umbrella group that calls itself the catholicismic front.', '\"they (isis) have become aggressive, and they have crossed the red line from trespassing to assaults to their extremist agenda,\" said judaism aloush, a spokesman for a rebel umbrella group that calls itself the judaismic front.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = 'cnn'\n",
    "sensitive_attr = 'religion'\n",
    "\n",
    "grouped_sentences = {}\n",
    "texts = []\n",
    "mutants = []\n",
    "\n",
    "if dataset == 'parallel':\n",
    "    df = pd.read_csv(f'./data/groups_kor_eng/{sensitive_attr}.csv')\n",
    "    \n",
    "    for i, row in tqdm(df.iterrows()):\n",
    "        # kor_sentence = row[\"원문\"]\n",
    "        eng_sentence = ' '.join(row[\"번역문\"].lower().split())\n",
    "        \n",
    "        texts.append(eng_sentence)\n",
    "        mutants.append(trans_sentence_by_sa(eng_sentence, sensitive_attribute=sensitive_attr))\n",
    "    \n",
    "elif dataset == 'cnn':\n",
    "    df = pd.read_csv(f'./data/CNN/{sensitive_attr}-cnn.csv')\n",
    "    \n",
    "    for i, row in tqdm(df.iterrows()):\n",
    "        eng_sentence = ' '.join(row[\"article\"].lower().split())\n",
    "        \n",
    "        texts.append(eng_sentence)\n",
    "        mutants.append(trans_sentence_by_sa(eng_sentence, sensitive_attribute=sensitive_attr))\n",
    "    \n",
    "print(texts[0])\n",
    "print(mutants[0])\n",
    "\n",
    "inconsistency_result = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1100/1100 [00:15<00:00, 72.31it/s]\n"
     ]
    }
   ],
   "source": [
    "translator = RemoteTranslator(\"Google\")\n",
    "\n",
    "for text, mutant_list in tqdm(list(zip(texts, mutants))[:10000]):\n",
    "    text_hash = mmh3.hash(text)\n",
    "    if text_hash in inconsistency_result:\n",
    "        continue\n",
    "    \n",
    "    text_translated = translator.translate(text, 'en', 'ko')\n",
    "    mutant_translated = [translator.translate(s_m, 'en', 'ko') for s_m in mutant_list]\n",
    "\n",
    "    is_consistent, scores = test_consistency(text_translated, mutant_translated)\n",
    "\n",
    "    # if not is_consistent:\n",
    "    inconsistency_result[text_hash] =  {\n",
    "        'original_sentence': (text, text_translated),\n",
    "        'mutants': [(m, t, s) for m, t, s in zip(mutant_list, mutant_translated, scores)],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'result/inconsistency_result/{sensitive_attr}_{dataset}.json', 'w') as f:\n",
    "    json.dump(inconsistency_result, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "878eaed65604c1104097ccdf5de881d73204f55acb592f52cbb5bd6ae899bb77"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('tensorflow-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
